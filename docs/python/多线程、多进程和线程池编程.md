---
title: 多线程、多进程和线程池编程
date: 2021-05-31
tags:
  - python
categories:
  - Python之旅
---

## python中的GIL（Global Interpreter Lock）

GIL：全局解释器锁（Cpython中才有，Jpython没有，pypy是去gil的）

cpython：python中的一个线程对应C语言的一个线程

gil使得同一个时刻只有一个线程在一个cpu上执行字节码，无法将多个线程映射到多cpu上

gil在一些情况下释放，是结合字节码和时间片释放（Python2和Python3有差别），gil在遇到io操作的时候会主动释放

```py
import threading

total = 1


def add():
    global total
    for i in range(1000000):
        total += 1


def decs():
    global total
    for i in range(1000000):
        total -= 1


thread1 = threading.Thread(target=add)
thread2 = threading.Thread(target=decs)

thread1.start()
thread2.start()

thread1.join()
thread2.join()

print(total) # 这里得到的是一个不确定的数值
```

## python多线程编程

1. **利用Thread实例实现多线程**

   这里子线程默认为非守护线程（主线程运行完，子线程不会退出，继续运行完）

   ```py
   import time
   import threading
   
   
   def get_detail_html(url):
       print("我获取详情内容了")
       time.sleep(2)
       print("我获取内容完了")
   
   
   def get_detail_url(url):
       print("我获取url了")
       time.sleep(2)
       print("我获取url完了")
   
   
   if __name__ == '__main__':
       thread1 = threading.Thread(target=get_detail_html, args=('', ))
       thread2 = threading.Thread(target=get_detail_url, args=('', ))
   
       start_time = time.time()
   
       thread1.start()
       thread2.start()
       '''
       这样运行一共有三个线程，主线程和其他两个子线程（thread1, thread2）
       而且是并行的，子线程启动后，主线程仍然往下运行，因此时间不是2秒
       '''
       # 守护线程（主线程退出，子线程就会kill掉）
       print('last time: {}'.format(time.time() - start_time))
   # 我获取详情内容了
   # 我获取url了
   # last time: 0.0009984970092773438
   # 我获取内容完了
   # 我获取url完了
   ```

2. **守护线程：（主线程退出，子线程就会被kill掉）**

   ```py
   import time
   import threading
   
   
   def get_detail_html(url):
       print("我获取详情内容了")
       time.sleep(4)
       print("我获取内容完了")
   
   
   def get_detail_url(url):
       print("我获取url了")
       time.sleep(2)
       print("我获取url完了")
   
   
   if __name__ == '__main__':
       thread1 = threading.Thread(target=get_detail_html, args=('', ))
       thread2 = threading.Thread(target=get_detail_url, args=('', ))
   
       # 将线程1设置成守护线程（主线程结束，该线程就会被kill掉），但会等线程2运行完（非守护线程）
       thread1.setDaemon(True)
   
       start_time = time.time()
   
       thread1.start()
       thread2.start()
   
       print('last time: {}'.format(time.time() - start_time))
   
   # 我获取详情内容了
   # 我获取url了
   # last time: 0.0009653568267822266
   # 我获取url完了
   ```

3. **join():等某个子线程执行完再继续执行主线程代码**

   ```py
   import time
   import threading
   
   
   def get_detail_html(url):
       print("我获取详情内容了")
       time.sleep(4)
       print("我获取内容完了")
   
   
   def get_detail_url(url):
       print("我获取url了")
       time.sleep(2)
       print("我获取url完了")
   
   
   if __name__ == '__main__':
       thread1 = threading.Thread(target=get_detail_html, args=('', ))
       thread2 = threading.Thread(target=get_detail_url, args=('', ))
   
       start_time = time.time()
   
       thread1.start()
       thread2.start()
   
       # 等待两个线程执行完
       thread1.join()
       thread2.join()
   
       print('last time: {}'.format(time.time() - start_time))
   
   # 我获取详情内容了
   # 我获取url了
   # 我获取url完了
   # 我获取内容完了
   # last time: 4.01223349571228
   ```

4. **继承Thread实现多线程**

   ```py
   import time
   import threading
   
   class GetDetailHtml(threading.Thread):
       def __init__(self, name):
           super().__init__(name=name)
           
       def run(self):
           print('我获取详情内容了')
           time.sleep(4)
           print('我获取内容完了')
       
   class GetDetailUrl(threading.Thread):
       def __init__(self, name):
           super().__init__(name=name)
           
       def run(self):
           print('我获取url了')
           time.sleep(2)
           print('我获取url完了')
   
   if __name__ == '__main__':
       thread1 = GetDetailHtml('get_detail_html')
       thread2 = GetDetailUrl('get_deatil_url')
       
       start_time = time.time()
       
       thread1.start()
       thread2.start()
       
       # 等待两个线程执行完
       thread1.join()
       thread2.join()
       
       print('last time: {}'.format(time.time() - start_time))
       
   # 我获取详情内容了
   # 我获取url了
   # 我获取url完了
   # 我获取内容完了
   # last time: 4.013352870941162
   ```

## 线程间通信-Queue

1. **线程通信方式——共享变量：（全局变量或参数等）**

   :::warning

   共享变量的方式是线程不安全的操作（不推荐）

   :::

   ```py
   import threading
   import time
   
   my_list = []
   
   
   def add_something():
       global my_list
       print("开始添加")
       time.sleep(1)
       for i in range(20):
           my_list.append(i)
       print("添加结束")
   
   
   def get_something():
       global my_list
       print("开始取出")
       time.sleep(2)
       while len(my_list):
           num = my_list.pop()
           print(num)
       print("取出结束")
   
   
   if __name__ == '__main__':
       thread1 = threading.Thread(target=add_something)
       thread2 = threading.Thread(target=get_something)
   
       thread1.start()
       thread2.start()
   ```

2. **通过queue的方式进行线程同步**

   :::tip

   线程是安全的（Queue本身就是线程安全的【使用了线程锁的机制】，使用了双端队列，deque）

   :::

   Queue中的方法：

   * `qsize()`查看队列大小
   * `empty()`判断队列是否为空
   * `full()`判断队列是否满，满了的话put方法就会阻塞，等待有空位加入
   * `put()`将数据放入队列，默认是阻塞的（block参数，可以设置成非阻塞，还有timeout等待时间）
   * `get()`从队列取数据

   ```py
   import threading
   import time
   from queue import Queue
   
   
   def add_something(queue):
       print("开始添加")
       time.sleep(1)
       for i in range(20):
           queue.put(i)
       print("添加结束")
   
   
   def get_something(queue):
       print("开始取出")
       time.sleep(2)
       while not queue.empty():
           num = queue.get()
           print(num)
       print("取出结束")
       my_queue.task_done()
   
   
   if __name__ == '__main__':
       my_queue = Queue(maxsize=30)
       thread1 = threading.Thread(target=add_something, args=(my_queue, ))
       thread2 = threading.Thread(target=get_something, args=(my_queue, ))
   
       thread1.start()
       thread2.start()
   
       # 执行task_done()才能执行退出，和join成对出现,通常在某个需要退出的地方执行
       my_queue.join()
   ```

## 线程同步(Lock、RLock、Condition、Semaphores)

1. **Lock：锁住的代码段都只能有一个代码段运行**

   获取（acquire）和释放（release）锁都需要时间：因此用锁会影响性能；还有可能引起死锁（互相等待，A和B都需要a，b两个资源，A获取了a，B获取了b，A等待b，B等待a或者未释放锁再次获取）

   产生死锁的四个条件：互斥条件、不剥夺条件、请求和保持条件、循环等待条件

   ```py
   import threading
   from threading import Lock
   
   total = 1
   lock = Lock()
   
   
   def add():
       global total
       for i in range(1000000):
           # 获取锁
           lock.acquire()
           total += 1
           # 释放锁，释放后其他才能获取
           lock.release()
   
   
   def decs():
       global total
       for i in range(1000000):
           lock.acquire()
           total -= 1
           lock.release()
   
   
   thread1 = threading.Thread(target=add)
   thread2 = threading.Thread(target=decs)
   
   thread1.start()
   thread2.start()
   thread1.join()
   thread2.join()
   print(total)
   ```

2. **RLock（可重入的锁）：在一个线程中可以连续多次acquire（获取资源）**

   :::tip

   **acquire的次数要和release的次数一致**

   :::

3. **Condition:条件变量（用于复杂的线程同步）**

   **3.1 使用锁进行先后对话：发现先启动的线程把话说完（第一个线程启动后运行完，第二个线程还没启动，或者还未切换到另一个线程）**

   **3.2 通过condition实现**

   通过调用with方法（实际是`__enter__`魔法函数），也可以使用acquire()方法，但一定要release()之后才能调用其他函数【wait()、`notify()`】，还有注意线程启动顺序【接收方先启动，否则接收不到】

   Condition有两层锁，会在线程调用了`wait()`方法时释放，上面的锁会在每次调用`wait()`时分配一把锁并放入到condition的等待队列中，等待`notify()`方法的唤醒

   ```py
   import threading
   
   
   class T1(threading.Thread):
       def __init__(self, cond):
           super().__init__(name="T1")
           self.cond = cond
   
       def run(self):
           with self.cond:
               print("T1: 你好，我是{}".format(self.name))
               self.cond.notify()
               self.cond.wait()
               print("T1:哈哈")
               self.cond.notify()
               self.cond.wait()
               print("T1:嘿嘿")
               self.cond.notify()
   
   
   class T2(threading.Thread):
       def __init__(self, cond):
           super().__init__(name="T2")
           self.cond = cond
   
       def run(self):
           with self.cond:
               self.cond.wait()
               print("T2:你好，我是{}".format(self.name))
               self.cond.notify()
               self.cond.wait()
               print("T2:嘻嘻")
               self.cond.notify()
               self.cond.wait()
               print("T2:呼呼")
   
   
   if __name__ == '__main__':
       cond = threading.Condition()
       t1 = T1(cond=cond)
       t2 = T2(cond=cond)
       # 注意启动顺序，如果先启动t1，发送通知却没有接收（t2还没启动）
       t2.start()
       t1.start()
   
   # T1: 你好，我是T1
   # T2:你好，我是T2
   # T1:哈哈        
   # T2:嘻嘻        
   # T1:嘿嘿        
   # T2:呼呼
   ```

4. **Semaphores：（有一个参数value可以控制线程（并发数），调用`acquire()`方法value就会减一，如果减少到0就会阻塞在那儿等待有空位，调用`release()`方法value就会加一）【线程数量过多会影响切换线程的效率】**

   Semaphores内部实质是用Condition完成的，Queue实质也是

   用来控制进入数量的锁（如文件写一般只能一个线程，读可以允许同时多个线程读）

   ```py
   from threading import Semaphore
   import threading
   import time
   
   
   class UrlProducer(threading.Thread):
       def __init__(self, sem):
           super().__init__()
           self.sem = sem
   
       def run(self):
           for i in range(20):
               # 调用acquire方法，Semaphore中的value就会减一（value），如果为0就阻塞在这
               self.sem.acquire()
               html_get = HtmlGet("url" + str(i), sem)
               html_get.start()
   
   
   class HtmlGet(threading.Thread):
       def __init__(self, url, sem):
           super().__init__()
           self.url = url
           self.sem = sem
   
       def run(self):
           time.sleep(2)
           print('获取网页成功')
           # 调用release方法，Semaphore中的value就会加一
           self.sem.release()
   
   
   if __name__ == '__main__':
       # 允许的并发数
       sem = Semaphore(3)
       url_producer = UrlProducer(sem)
       url_producer.start()
   ```

## concurrent线程池编码

**1. 为什么需要线程池**

​	提供了数量控制，获取线程的状态及返回值。挡一个线程完成的时候主线程能立即知道，futures能让多线程和多进程编码接口一致

**2. ThreadPoolExecutor中重要函数**

​	`submit()`：通过submit函数提交执行的函数到线程池，立即返回值（不会阻塞）

​	`done()`：判断某个任务是否执行成功
​	`result()`：获取返回值

​	`cancel()`：取消某个任务（还未执行，执行中不能取消）

​	`wait()`：让主线程阻塞等待子线程完成，可以添加参数等待多长时间就不等待了

**3. 获取已完成的任务**

​	`as_completed()`【from concurrent.futures import ThreadPoolExecutor, as_completed】

​	`map`(属于ThreadPoolExecutor)

```py
from concurrent.futures import ThreadPoolExecutor, as_completed, wait
import time


def get_html(times):
    time.sleep(times)
    print('get success {}'.format(times))
    return times


excutor = ThreadPoolExecutor(max_workers=2)

# # 通过submit函数提交执行的函数到线程池，立即返回值（不会阻塞）
# ret1 = excutor.submit(get_html, (3))

# # 通过done()判断函数是否执行成功
# print("ret1 done:", ret1.done())
# print("ret1 cancel:", ret1.cancel())

# ret2 = excutor.submit(get_html, (2))
# print("ret2 done", ret2.done())

# # 获取返回值
# print("ret1 result:", ret1.result())

urls = [2, 3, 4]

# 获取已经完成的任务
# all_task = [excutor.submit(get_html, (url)) for url in urls]
# wait（让主线程阻塞等待子线程完成）
# wait(all_task, return_when='FIRST_COMPLETED')
# print('FIRST_COMPLETED')

# for future in as_completed(all_task):
#     data = future.result()
#     print(data)

for data in excutor.map(get_html, urls):
    print("data:", data)
```

## 多进程编程-Multiprocessing

### **1. 和多线程对比**

​	1.1 多进程开销大，多线程开销小

​	1.2 耗CPU的操作，多进程编程比多线程编程好很多，对应IO操作来说，使用多线程操作比多进程号（线程切换比进程切换性能高）

### **2. 例**

对于耗CPU的操作（多进程优于多线程）

```py
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed
import time


def fib(n):
    if n <= 2:
        return 1
    return fib(n - 2) + fib(n - 1)


if __name__ == "__main__":
    with ThreadPoolExecutor(3) as excutor:
        start_time = time.time()
        all_task = [excutor.submit(fib, num) for num in range(22, 40)]

        for future in as_completed(all_task):
            data = future.result()
            print("结果：", str(data))
        print("多线程所需时间:", str(time.time() - start_time))
        # 25.312673330307007

    with ProcessPoolExecutor(3) as excutor:
        start_time = time.time()
        all_task = [excutor.submit(fib, num) for num in range(25, 40)]

        for future in as_completed(all_task):
            data = future.result()
            print("结果：", str(data))
        print("多进程所需时间:", str(time.time() - start_time))
        # 14.332133769989014
```

对于IO操作，多线程优于多进程

```py
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed
import time


def random_sleep(n):
    time.sleep(n)
    return n


if __name__ == "__main__":
    with ThreadPoolExecutor(3) as excutor:
        start_time = time.time()
        all_task = [excutor.submit(random_sleep, num) for num in [2] * 30]

        for future in as_completed(all_task):
            data = future.result()
            print("结果：", str(data))
        print("多线程所需时间:", str(time.time() - start_time))
        # 20.08771586418152

    with ProcessPoolExecutor(3) as excutor:
        start_time = time.time()
        all_task = [excutor.submit(random_sleep, num) for num in [2] * 30]

        for future in as_completed(all_task):
            data = future.result()
            print("结果：", str(data))
        print("多进程所需时间:", str(time.time() - start_time))
        # 20.236736297607422
```

### **3. multiprocessing：（比ProcessPoolExecutor更底层【基于multiprocessing实现】）**

```py
import time
import multiprocessing
def get_html(n):
    time.sleep(n)
    print('sub_process success')
    return n

if __name__ == "__main__":
    process = multiprocessing.Process(target=get_html, args=(1,))
    # 获取进程号，没有start之前为None
    print(process.pid)
    process.start()
    print(process.pid)
    process.join()
    print('main_process success')
    
# None
# 7504
# sub_process success
# main_process success
```

### **4. 进程池**

```py
import time
import multiprocessing
def get_html(n):
    time.sleep(n)
    print('sub_process success')
    return n

if __name__ == "__main__":
    pool = multiprocessing.Pool(3)
    # 异步提交任务
    # result = pool.apply_async(get_html, args=(2,))
    # 关闭不再进入进程池
    # pool.close()
    # pool.join()
    # print(result.get())
    
    # 和执行顺序一样
    for result in pool.imap(get_html, [1, 5, 3]):
        print("{} sleep success".format(result))
    # 1 5 3
        
    # 和先后完成顺序一样
    for result in pool.imap_unordered(get_html, [1, 5, 3]):
        print("{} sleep success".format(result))
    # 1 3 5
```

## 进程间通信

**1. 共享全局变量在多进程中不适用（会把数据复杂到子进程中，数据是独立的，修改也不会影响），queue中的Queue也不行，需要做一些处理**

```py
from multiprocessing import Queue, Process
import time


def producer(queue):
    queue.put('a')
    time.sleep(2)


def consumer(queue):
    time.sleep(2)
    data = queue.get()
    print(data)


if __name__ == '__main__':
    queue = Queue(10)
    pro_producer = Process(target=producer, args=(queue, ))
    pro_consumer = Process(target=consumer, args=(queue, ))
    pro_producer.start()
    pro_consumer.start()
    pro_producer.join()
    pro_consumer.join()
```

**2. multiprocessing中的Queue不能用于进程池（需要用到manager）**

queue = Managet().Queue(10)

```py
from queue import Queue # 用于多线程
from multprocessing import Queue # 用于非进程池的多进程通信
from multprocessing import Manager # managet.Queue()用于进程池通信
```

**3. 通过Pipe进行进程间通信（管道），pipe只能适用于两个进程，Pipe性能高于queue**

```py
from multiprocessing import Pipe, Manager, Process
import time


def producer(pipe):
    pipe.send('a')
    time.sleep(2)


def consumer(pipe):
    time.sleep(2)
    data = pipe.recv()
    print(data)


if __name__ == "__main__":
    # 通过Pipe进行进程间通信（管道），pipe只能适用于两个进程
    recv_pipe, send_pipe = Pipe()
    queue = Manager().Queue(10)
    pro_producer = Process(target=producer, args=(send_pipe, ))
    pro_consumer = Process(target=consumer, args=(recv_pipe,))
    pro_producer.start()
    pro_consumer.start()
    pro_producer.join()
    pro_consumer.join()
```

**4. 进程间共享内存（Managet）**

```py
from multiprocessing import Manager, Process


def add_data(pro_dict, key, value):
    pro_dict[key] = value


if __name__ == "__main__":
    process_dict = Manager().dict()
    fir = Process(target=add_data, args=(process_dict, 'name1', 'kellen1'))
    sed = Process(target=add_data, args=(process_dict, 'name2', 'kellen2'))
    fir.start()
    sed.start()
    fir.join()
    sed.join()
    print(process_dict) # {'name1': 'kellen1', 'name2': 'kellen2'}
```

